{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von GaitEvent_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy6BlDoqv7hp"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM37HmJ10Q0t"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLTeu1esD_-Q",
        "outputId": "31a1eecc-a1f3-41d9-e493-ae2ce739f8af"
      },
      "source": [
        "# Install miniconda environment\n",
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.9/site-packages/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-01 12:01:16--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 66709754 (64M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>]  63.62M   228MB/s    in 0.3s    \n",
            "\n",
            "2021-09-01 12:01:16 (228 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [66709754/66709754]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - _openmp_mutex==4.5=1_gnu\n",
            "    - brotlipy==0.7.0=py39h27cfd23_1003\n",
            "    - ca-certificates==2021.7.5=h06a4308_1\n",
            "    - certifi==2021.5.30=py39h06a4308_0\n",
            "    - cffi==1.14.6=py39h400218f_0\n",
            "    - chardet==4.0.0=py39h06a4308_1003\n",
            "    - conda-package-handling==1.7.3=py39h27cfd23_1\n",
            "    - conda==4.10.3=py39h06a4308_0\n",
            "    - cryptography==3.4.7=py39hd23ed53_0\n",
            "    - idna==2.10=pyhd3eb1b0_0\n",
            "    - ld_impl_linux-64==2.35.1=h7274673_9\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.3.0=h5101ec6_17\n",
            "    - libgomp==9.3.0=h5101ec6_17\n",
            "    - libstdcxx-ng==9.3.0=hd4cf53a_17\n",
            "    - ncurses==6.2=he6710b0_1\n",
            "    - openssl==1.1.1k=h27cfd23_0\n",
            "    - pip==21.1.3=py39h06a4308_0\n",
            "    - pycosat==0.6.3=py39h27cfd23_0\n",
            "    - pycparser==2.20=py_2\n",
            "    - pyopenssl==20.0.1=pyhd3eb1b0_1\n",
            "    - pysocks==1.7.1=py39h06a4308_0\n",
            "    - python==3.9.5=h12debd9_4\n",
            "    - readline==8.1=h27cfd23_0\n",
            "    - requests==2.25.1=pyhd3eb1b0_0\n",
            "    - ruamel_yaml==0.15.100=py39h27cfd23_0\n",
            "    - setuptools==52.0.0=py39h06a4308_0\n",
            "    - six==1.16.0=pyhd3eb1b0_0\n",
            "    - sqlite==3.36.0=hc218d9a_0\n",
            "    - tk==8.6.10=hbc83047_0\n",
            "    - tqdm==4.61.2=pyhd3eb1b0_1\n",
            "    - tzdata==2021a=h52ac0ba_0\n",
            "    - urllib3==1.26.6=pyhd3eb1b0_1\n",
            "    - wheel==0.36.2=pyhd3eb1b0_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py39h27cfd23_1003\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2021.7.5-h06a4308_1\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.5.30-py39h06a4308_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.6-py39h400218f_0\n",
            "  chardet            pkgs/main/linux-64::chardet-4.0.0-py39h06a4308_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.10.3-py39h06a4308_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.7.3-py39h27cfd23_1\n",
            "  cryptography       pkgs/main/linux-64::cryptography-3.4.7-py39hd23ed53_0\n",
            "  idna               pkgs/main/noarch::idna-2.10-pyhd3eb1b0_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.35.1-h7274673_9\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n",
            "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1k-h27cfd23_0\n",
            "  pip                pkgs/main/linux-64::pip-21.1.3-py39h06a4308_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py39h27cfd23_0\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.20-py_2\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-20.0.1-pyhd3eb1b0_1\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py39h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.9.5-h12debd9_4\n",
            "  readline           pkgs/main/linux-64::readline-8.1-h27cfd23_0\n",
            "  requests           pkgs/main/noarch::requests-2.25.1-pyhd3eb1b0_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.100-py39h27cfd23_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-52.0.0-py39h06a4308_0\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.36.0-hc218d9a_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.61.2-pyhd3eb1b0_1\n",
            "  tzdata             pkgs/main/noarch::tzdata-2021a-h52ac0ba_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.6-pyhd3eb1b0_1\n",
            "  wheel              pkgs/main/noarch::wheel-0.36.2-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m319jx6iECIq",
        "outputId": "dab7959c-f1b6-4dd9-e6cf-0132e3d00170"
      },
      "source": [
        "!pip -q install optuna\n",
        "!pip -q install rdp\n",
        "!pip -q install vg\n",
        "!conda install -q -y --prefix /usr/local -c pyomeca -c conda-forge pyomeca"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 302 kB 14.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 28.5 MB 70 kB/s \n",
            "\u001b[K     |████████████████████████████████| 208 kB 85.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 7.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 630 kB 60.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 57.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 15.8 MB 21 kB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 77.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 141 kB 93.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 77.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.2 MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "  Building wheel for rdp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - pyomeca\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    bottleneck-1.3.2           |   py39hce5d2b2_3         130 KB  conda-forge\n",
            "    ca-certificates-2021.5.30  |       ha878542_0         136 KB  conda-forge\n",
            "    certifi-2021.5.30          |   py39hf3d152e_0         141 KB  conda-forge\n",
            "    conda-4.10.3               |   py39hf3d152e_0         3.1 MB  conda-forge\n",
            "    cycler-0.10.0              |             py_2           9 KB  conda-forge\n",
            "    et_xmlfile-1.0.1           |          py_1001          11 KB  conda-forge\n",
            "    ezc3d-1.4.5                |   py39h5472131_0         773 KB  conda-forge\n",
            "    freetype-2.10.4            |       h0708190_1         890 KB  conda-forge\n",
            "    jbig-2.1                   |    h7f98852_2003          43 KB  conda-forge\n",
            "    jdcal-1.4.1                |             py_0           9 KB  conda-forge\n",
            "    jpeg-9d                    |       h36c2ea0_0         264 KB  conda-forge\n",
            "    kiwisolver-1.3.1           |   py39h2531618_0          80 KB\n",
            "    lcms2-2.12                 |       hddcbb42_0         443 KB  conda-forge\n",
            "    lerc-2.2.1                 |       h9c3ff4c_0         213 KB  conda-forge\n",
            "    libblas-3.9.0              |11_linux64_openblas          12 KB  conda-forge\n",
            "    libcblas-3.9.0             |11_linux64_openblas          11 KB  conda-forge\n",
            "    libdeflate-1.7             |       h7f98852_5          67 KB  conda-forge\n",
            "    libgfortran-ng-11.1.0      |       h69a702a_8          19 KB  conda-forge\n",
            "    libgfortran5-11.1.0        |       h6c583b3_8         1.7 MB  conda-forge\n",
            "    liblapack-3.9.0            |11_linux64_openblas          11 KB  conda-forge\n",
            "    libopenblas-0.3.17         |pthreads_h8fe5266_1         9.2 MB  conda-forge\n",
            "    libpng-1.6.37              |       h21135ba_2         306 KB  conda-forge\n",
            "    libtiff-4.3.0              |       hf544144_1         668 KB  conda-forge\n",
            "    libwebp-base-1.2.0         |       h27cfd23_0         437 KB\n",
            "    lz4-c-1.9.3                |       h9c3ff4c_1         179 KB  conda-forge\n",
            "    matplotlib-base-3.3.4      |   py39h2fa2bec_0         6.7 MB  conda-forge\n",
            "    numpy-1.20.3               |   py39hdbf815f_1         5.8 MB  conda-forge\n",
            "    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n",
            "    openjpeg-2.4.0             |       hb52868f_1         444 KB  conda-forge\n",
            "    openpyxl-3.0.7             |     pyhd8ed1ab_0         154 KB  conda-forge\n",
            "    openssl-1.1.1k             |       h7f98852_0         2.1 MB  conda-forge\n",
            "    pandas-1.3.0               |   py39hde0f152_0        13.0 MB  conda-forge\n",
            "    pillow-8.3.1               |   py39ha612740_0         687 KB  conda-forge\n",
            "    pyomeca-2021.0.1           |     pyh44b312d_0          35 KB  conda-forge\n",
            "    pyparsing-2.4.7            |     pyh9f0ad1d_0          60 KB  conda-forge\n",
            "    python-dateutil-2.8.2      |     pyhd8ed1ab_0         240 KB  conda-forge\n",
            "    python_abi-3.9             |           2_cp39           4 KB  conda-forge\n",
            "    pytz-2021.1                |     pyhd8ed1ab_0         239 KB  conda-forge\n",
            "    scipy-1.6.3                |   py39hee8e79c_0        20.7 MB  conda-forge\n",
            "    tornado-6.1                |   py39h3811e60_1         646 KB  conda-forge\n",
            "    xarray-0.19.0              |     pyhd8ed1ab_1         614 KB  conda-forge\n",
            "    zstd-1.5.0                 |       ha95c52a_0         490 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        70.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  bottleneck         conda-forge/linux-64::bottleneck-1.3.2-py39hce5d2b2_3\n",
            "  cycler             conda-forge/noarch::cycler-0.10.0-py_2\n",
            "  et_xmlfile         conda-forge/noarch::et_xmlfile-1.0.1-py_1001\n",
            "  ezc3d              conda-forge/linux-64::ezc3d-1.4.5-py39h5472131_0\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n",
            "  jbig               conda-forge/linux-64::jbig-2.1-h7f98852_2003\n",
            "  jdcal              conda-forge/noarch::jdcal-1.4.1-py_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9d-h36c2ea0_0\n",
            "  kiwisolver         pkgs/main/linux-64::kiwisolver-1.3.1-py39h2531618_0\n",
            "  lcms2              conda-forge/linux-64::lcms2-2.12-hddcbb42_0\n",
            "  lerc               conda-forge/linux-64::lerc-2.2.1-h9c3ff4c_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-11_linux64_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-11_linux64_openblas\n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.7-h7f98852_5\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-11.1.0-h69a702a_8\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-11.1.0-h6c583b3_8\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-11_linux64_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.17-pthreads_h8fe5266_1\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.3.0-hf544144_1\n",
            "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.0-h27cfd23_0\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.9.3-h9c3ff4c_1\n",
            "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.3.4-py39h2fa2bec_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.20.3-py39hdbf815f_1\n",
            "  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n",
            "  openjpeg           conda-forge/linux-64::openjpeg-2.4.0-hb52868f_1\n",
            "  openpyxl           conda-forge/noarch::openpyxl-3.0.7-pyhd8ed1ab_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.3.0-py39hde0f152_0\n",
            "  pillow             conda-forge/linux-64::pillow-8.3.1-py39ha612740_0\n",
            "  pyomeca            conda-forge/noarch::pyomeca-2021.0.1-pyh44b312d_0\n",
            "  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.9-2_cp39\n",
            "  pytz               conda-forge/noarch::pytz-2021.1-pyhd8ed1ab_0\n",
            "  scipy              conda-forge/linux-64::scipy-1.6.3-py39hee8e79c_0\n",
            "  tornado            conda-forge/linux-64::tornado-6.1-py39h3811e60_1\n",
            "  xarray             conda-forge/noarch::xarray-0.19.0-pyhd8ed1ab_1\n",
            "  zstd               conda-forge/linux-64::zstd-1.5.0-ha95c52a_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2021.7.5-h~ --> conda-forge::ca-certificates-2021.5.30-ha878542_0\n",
            "  certifi            pkgs/main::certifi-2021.5.30-py39h06a~ --> conda-forge::certifi-2021.5.30-py39hf3d152e_0\n",
            "  conda              pkgs/main::conda-4.10.3-py39h06a4308_0 --> conda-forge::conda-4.10.3-py39hf3d152e_0\n",
            "  openssl              pkgs/main::openssl-1.1.1k-h27cfd23_0 --> conda-forge::openssl-1.1.1k-h7f98852_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMeThIoCaNVN"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LayerNormLSTMCell(nn.LSTMCell):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, bias=True):\n",
        "        super().__init__(input_size, hidden_size, bias)\n",
        "\n",
        "        self.ln_ih = nn.LayerNorm(4 * hidden_size)\n",
        "        self.ln_hh = nn.LayerNorm(4 * hidden_size)\n",
        "        self.ln_ho = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        self.check_forward_input(input)\n",
        "        if hidden is None:\n",
        "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
        "            cx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
        "        else:\n",
        "            hx, cx = hidden\n",
        "        self.check_forward_hidden(input, hx, '[0]')\n",
        "        self.check_forward_hidden(input, cx, '[1]')\n",
        "\n",
        "        gates = self.ln_ih(F.linear(input, self.weight_ih, self.bias_ih)) \\\n",
        "                 + self.ln_hh(F.linear(hx, self.weight_hh, self.bias_hh))\n",
        "        i, f, o = gates[:, :(3 * self.hidden_size)].sigmoid().chunk(3, 1)\n",
        "        g = gates[:, (3 * self.hidden_size):].tanh()\n",
        "\n",
        "        cy = (f * cx) + (i * g)\n",
        "        hy = o * self.ln_ho(cy).tanh()\n",
        "        return hy, cy\n",
        "\n",
        "\n",
        "class LayerNormLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, bias=True, \n",
        "                 bidirectional=False, batch_first=False):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.batch_first = batch_first\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        self.hidden0 = nn.ModuleList([\n",
        "            LayerNormLSTMCell(input_size=(input_size if layer == 0 else hidden_size * num_directions),\n",
        "                              hidden_size=hidden_size, bias=bias)\n",
        "            for layer in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        if self.bidirectional:\n",
        "            self.hidden1 = nn.ModuleList([\n",
        "                LayerNormLSTMCell(input_size=(input_size if layer == 0 else hidden_size * num_directions),\n",
        "                                  hidden_size=hidden_size, bias=bias)\n",
        "                for layer in range(num_layers)\n",
        "            ])\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        if self.batch_first: # (batch, seq, feature) instead of (seq, batch, feature)\n",
        "            input = input.transpose(0, 1)\n",
        "        seq_len, batch_size, hidden_size = input.size()  # supports TxNxH only\n",
        "        num_directions = 2 if self.bidirectional else 1\n",
        "        if hidden is None:\n",
        "            hx = input.new_zeros(self.num_layers * num_directions, batch_size, self.hidden_size, requires_grad=False)\n",
        "            cx = input.new_zeros(self.num_layers * num_directions, batch_size, self.hidden_size, requires_grad=False)\n",
        "        else:\n",
        "            hx, cx = hidden\n",
        "\n",
        "        ht = [[None, ] * (self.num_layers * num_directions)] * seq_len\n",
        "        ct = [[None, ] * (self.num_layers * num_directions)] * seq_len\n",
        "\n",
        "        if self.bidirectional:\n",
        "            xs = input\n",
        "            for l, (layer0, layer1) in enumerate(zip(self.hidden0, self.hidden1)):\n",
        "                l0, l1 = 2 * l, 2 * l + 1\n",
        "                h0, c0, h1, c1 = hx[l0], cx[l0], hx[l1], cx[l1]\n",
        "                for t, (x0, x1) in enumerate(zip(xs, reversed(xs))):\n",
        "                    ht[t][l0], ct[t][l0] = layer0(x0, (h0, c0))\n",
        "                    h0, c0 = ht[t][l0], ct[t][l0]\n",
        "                    t = seq_len - 1 - t\n",
        "                    ht[t][l1], ct[t][l1] = layer1(x1, (h1, c1))\n",
        "                    h1, c1 = ht[t][l1], ct[t][l1]\n",
        "                xs = [torch.cat((h[l0], h[l1]), dim=1) for h in ht]\n",
        "            y  = torch.stack(xs)\n",
        "            hy = torch.stack(ht[-1])\n",
        "            cy = torch.stack(ct[-1])\n",
        "        else:\n",
        "            h, c = hx, cx\n",
        "            for t, x in enumerate(input):\n",
        "                for l, layer in enumerate(self.hidden0):\n",
        "                    ht[t][l], ct[t][l] = layer(x, (h[l], c[l]))\n",
        "                    x = ht[t][l]\n",
        "                h, c = ht[t], ct[t]\n",
        "            y  = torch.stack([h[-1] for h in ht])\n",
        "            hy = torch.stack(ht[-1])\n",
        "            cy = torch.stack(ct[-1])\n",
        "        \n",
        "\n",
        "        if self.batch_first:\n",
        "            y = y.permute(0,1)\n",
        "\n",
        "        return y, (hy, cy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTBLa9nwNqLP"
      },
      "source": [
        "#A multimodal dataset of human gait at different walking speeds established on injury-free adult participants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seFW1dHxNCFe"
      },
      "source": [
        "Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkZlyoCBNsNb"
      },
      "source": [
        "!wget -q https://ndownloader.figshare.com/files/22295019 -O dataset.zip\n",
        "!unzip -qq dataset.zip\n",
        "!rm dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deTv88BYPUNA"
      },
      "source": [
        "## Define helper methods and classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQBcaewRNEq2"
      },
      "source": [
        "Define helper methods to load the c3d files and preprocess them for the RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kjPS_EWNwDL"
      },
      "source": [
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from pyomeca import Markers, Analogs\n",
        "from scipy.interpolate import interp1d\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import vg\n",
        "\n",
        "PELVIS, RHIP, LHIP, RKNEE, LKNEE, RANKLE, LANKLE, VPELVIS, VRANKLE, VLANKLE = range(10)\n",
        "\n",
        "def create_features(markers, in_freq=100, out_freq=-1):\n",
        "    n_features = 10\n",
        "    data = np.zeros((len(markers.axis), n_features, len(markers.time))) #(axis, joint, frame)\n",
        "    # define pelvis, hip, knee and ankle joints from markers\n",
        "    data[:, PELVIS] = markers.loc[:, ['R_IAS', 'L_IAS', 'R_IPS', 'L_IPS']].mean(axis=1).values\n",
        "    data[:, RHIP] = 0.5 * (markers.loc[:, 'R_FTC'] + data[:, PELVIS])\n",
        "    data[:, LHIP] = 0.5 * (markers.loc[:, 'L_FTC'] + data[:, PELVIS])\n",
        "    data[:, RKNEE] = markers.loc[:, ['R_FLE', 'R_FME']].mean(axis=1).values\n",
        "    data[:, LKNEE] = markers.loc[:, ['L_FLE', 'L_FME']].mean(axis=1).values\n",
        "    data[:, RANKLE] = markers.loc[:, ['R_FAL', 'R_TAM']].mean(axis=1).values\n",
        "    data[:, LANKLE] = markers.loc[:, ['L_FAL', 'L_TAM']].mean(axis=1).values\n",
        "    data[:, VPELVIS:] = np.gradient(data[:, PELVIS], axis=-1)\n",
        "    data[:, VRANKLE:VLANKLE+1] = np.gradient(data[:, RANKLE:LANKLE+1], axis=-1)\n",
        "    #joint locations relative to pelvis\n",
        "    data[:, RHIP:LANKLE+1] -= data[:, [PELVIS]]\n",
        "    # pelvis relative to first frame\n",
        "    data[:, PELVIS] -= data[:, PELVIS, [0]]\n",
        "    # swap axes and reshape to (frame, channel)\n",
        "    data = data.transpose([2,1,0]) # (frame, joint, axis)\n",
        "    data = data.reshape(len(markers.time), -1) # (frame, joint * axis)    \n",
        "    # up/downsampling if necessary\n",
        "    if out_freq != -1 and in_freq != out_freq:\n",
        "        scale_factor = in_freq // out_freq # should be a multiple\n",
        "        old_x = np.linspace(0, 1, len(data))\n",
        "        new_x = np.linspace(0, 1, len(data) // scale_factor)\n",
        "        data = np.apply_along_axis(\n",
        "            lambda y: interp1d(old_x, y, kind = 'cubic')(new_x),\n",
        "            arr=data, axis=0\n",
        "        )\n",
        "    return data\n",
        "\n",
        "def _norm_walking_dir(feature):\n",
        "    x_axis = np.array([1,0,0])\n",
        "    z_axis = np.array([0,0,1])\n",
        "\n",
        "    orient = vg.angle((feature[:, LHIP] - feature[:, RHIP]), x_axis, look=z_axis)\n",
        "    new_feature = feature.copy()\n",
        "    for i in range(RHIP, LANKLE+1):\n",
        "        new_feature[i] = vg.rotate(feature[i], z_axis, orient[i])\n",
        "    return new_feature\n",
        "\n",
        "\n",
        "def detect_step(v_force, treshold=10):\n",
        "    step = v_force.meca.detect_onset(threshold=treshold, n_above=10, n_below=10)\n",
        "    if step.size < 2:\n",
        "        return [] # no step detected\n",
        "    hs, to = step[0]\n",
        "    return [hs, to]\n",
        "\n",
        "\n",
        "def load_c3d_files(path, freq=100, cut_cycle=True):\n",
        "    path = Path(path)\n",
        "    landmarks = ['R_IAS', 'L_IAS', 'R_IPS', 'L_IPS', 'R_FTC', 'L_FTC', 'R_FLE', 'L_FLE', \n",
        "                 'R_FME', 'L_FME', 'R_FAL', 'L_FAL', 'R_TAM', 'L_TAM']\n",
        "    channels = ['Fz1', 'Fz2']\n",
        "\n",
        "    meta = []\n",
        "    features = []\n",
        "    targets = []\n",
        "\n",
        "    for p in path.glob('*/*_C*.c3d'):\n",
        "        name = p.stem\n",
        "        id = int(name[4:7])\n",
        "        cond = int(name[9])\n",
        "        trial = int(name[-2:])\n",
        "\n",
        "        grfs = -Analogs.from_c3d(p, suffix_delimiter=\".\", usecols=channels)\n",
        "        GRF_FREQ = int(grfs.attrs['rate'])\n",
        "        step1 = detect_step(grfs.sel(channel='Fz1'))\n",
        "        step2 = detect_step(grfs.sel(channel='Fz2'))\n",
        "\n",
        "        # skip trials with missed steps\n",
        "        if not step1 or not step2: \n",
        "            continue\n",
        "        steps = np.array([step1, step2]).transpose() # [[hs1,hs2],[to1,to2]]\n",
        "        # downsample to target freq\n",
        "        steps = steps / (GRF_FREQ // freq)\n",
        "        steps = np.round(steps).astype(int)\n",
        "        if np.any(np.diff(steps, axis=0) < 10): # way to less for a correct detection\n",
        "            continue\n",
        "\n",
        "        markers = Markers.from_c3d(p, prefix_delimiter=\":\")#, usecols=landmarks)\n",
        "        if not np.isin(landmarks, markers.channel).all(): #missing marker\n",
        "            continue\n",
        "        MARKER_FREQ = int(markers.attrs['rate'])\n",
        "        markers = markers / 1000\n",
        "        feature = create_features2(markers.sel(axis=['y','x','z']),\n",
        "                                  MARKER_FREQ, freq)\n",
        "        \n",
        "        v_pelvis = feature[:, VPELVIS*3+0]\n",
        "        walking_dir = int(np.sign(np.mean(v_pelvis))) # +1 or -1\n",
        "\n",
        "        gait_events = np.zeros((len(feature), 4)) # (N, [rhs,lhs,rto,lto])\n",
        "        for i in range(4):\n",
        "            t = max(0, min(len(feature)-1, steps[i//2, i%2])) # edge cases\n",
        "            gait_events[t, i] = 1\n",
        "\n",
        "        if cut_cycle:\n",
        "            # only timespan with event detection\n",
        "            step_lens = walking_dir * np.diff(steps[0]).item() #diff rhs - lhs\n",
        "            start = max(0, int(np.min(steps[0]) - step_lens/4))\n",
        "            end = min(len(feature), int(np.max(steps[1]) + step_lens/4))\n",
        "            feature = feature[start:end]\n",
        "            gait_events = gait_events[start:end]\n",
        "\n",
        "        meta.append((id, cond, trial, walking_dir))\n",
        "        features.append(feature)\n",
        "        targets.append(gait_events)\n",
        "\n",
        "    meta = pd.DataFrame(meta, columns=['id', 'cond', 'trial', 'walking_dir'])\n",
        "    return features, targets, meta\n",
        "\n",
        "\n",
        "def prepare_for_rnn(features, targets, meta, event='both'):\n",
        "    rnn_features = []\n",
        "    rnn_targets = []\n",
        "    rnn_meta = pd.concat([meta, meta])\n",
        "\n",
        "    for i in range(len(features)):\n",
        "        f = features[i].reshape((-1, 10, 3))\n",
        "        t = targets[i]  # [rhs,lhs,rto,lto]\n",
        "        mhip = (f[:, [RHIP]] + f[:, [LHIP]]) / 2\n",
        "        f = f - mhip # set mhip as zero instead of pelvis\n",
        "        f = _norm_walking_dir(f)\n",
        "        # debias (devide by femur len)\n",
        "        femur_len_r = np.linalg.norm(f[:, RHIP] - f[:, RKNEE], axis=-1)\n",
        "        femur_len_l = np.linalg.norm(f[:, LHIP] - f[:, LKNEE], axis=-1)\n",
        "        femur_len = (femur_len_r + femur_len_l) / 2         # avg femur length in each frame\n",
        "        f = f / femur_len[:, None, None]      # normalize each frame\n",
        "\n",
        "        # create reduced feature set ignoring side\n",
        "        for side in [0,1]: # right, left\n",
        "            hs = t[:, side].nonzero()[0][0]\n",
        "            to = t[:, 2+side].nonzero()[0][0]\n",
        "            eps = np.int(0.33 * (to - hs)) # a third of a step\n",
        "            start = max(0, hs - eps)\n",
        "            end = min(len(f), to + eps)\n",
        "\n",
        "            nf = np.zeros((end-start, 6, 3))\n",
        "            nf[:, 0] = f[start:end, RHIP + side]\n",
        "            nf[:, 1] = f[start:end, RKNEE + side]\n",
        "            nf[:, 2] = f[start:end, RANKLE + side]\n",
        "            nf[:, 3:6] = np.gradient(nf[:, :3], axis=0) # velocities\n",
        "\n",
        "            nf = nf.reshape((len(nf), -1))\n",
        "            if event == 'HS':\n",
        "                nt = np.zeros((end-start, 1))\n",
        "                nt[:,0] = t[start:end, side]\n",
        "            elif event == 'TO':\n",
        "                nt = np.zeros((end-start, 1))\n",
        "                nt[:,0] = t[start:end, 2+side]\n",
        "            else:\n",
        "                nt = np.zeros((end-start, 2))\n",
        "                nt[:, 0] = t[start:end, side]\n",
        "                nt[:, 1] = t[start:end, 2+side]\n",
        "\n",
        "            rnn_features.append(nf)\n",
        "            rnn_targets.append(nt)\n",
        "\n",
        "    return rnn_features, rnn_targets, rnn_meta\n",
        "\n",
        "\n",
        "def load_dataset(path, freq=50):\n",
        "    data = load_c3d_files(path, freq=freq, cut_cycle=False)\n",
        "    return prepare_for_rnn(*data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdq042nWNM2x"
      },
      "source": [
        "Define the PyTorch Dataset, DataLoader, the RNN Module and the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki2IKYXhPYko"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import itertools as it\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "class GaitDataset(Dataset):\n",
        "    def __init__(self, features, targets, scaler, window_size=32, stride=8, transform=None):\n",
        "        #mean, std = scale\n",
        "        X = []\n",
        "        y = []\n",
        "        for f, t in zip(features, targets):\n",
        "            f_norm = scaler.transform(f) #(f - mean) / std\n",
        "            X.append(self._sliding_view(f_norm, window=window_size, stride=stride))\n",
        "            y.append(self._sliding_view(t, window=window_size, stride=stride))\n",
        "        \n",
        "        self.X = np.concatenate(X)\n",
        "        self.y = np.concatenate(y)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = (self.X[idx], self.y[idx])\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        X, y = sample\n",
        "        return torch.Tensor(X), torch.Tensor(y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def _sliding_view(self, array, start=0, window=3, stride=1):    \n",
        "        sub_windows = (\n",
        "            start + \n",
        "            np.expand_dims(np.arange(window), 0) +\n",
        "            np.expand_dims(np.arange(len(array) - window + 1), 0).T\n",
        "        )\n",
        "        return array[sub_windows[::stride]]\n",
        "\n",
        "class RandomNoise(object):\n",
        "    def __init__(self, sigma=0.01):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        x, y = sample\n",
        "        return x + np.random.normal(0, self.sigma, x.shape), y\n",
        "\n",
        "class RandomRotate(object):\n",
        "\n",
        "  def __init__(self, min_angle=0, max_angle=2*np.pi, unit='rad', axis='z', order='xyz'):\n",
        "      super(RandomRotate, self).__init__()\n",
        "      self.axis = np.zeros(3)\n",
        "      self.axis[order.index(axis)] = 1\n",
        "      self.min_angle = min_angle if unit == 'rad' else np.deg2rad(min_angle)\n",
        "      self.max_angle = max_angle if unit == 'rad' else np.deg2rad(max_angle)\n",
        "\n",
        "  def __call__(self, sample):\n",
        "      x, y = sample\n",
        "      new_x = x.copy()\n",
        "      angle = random.uniform(self.min_angle, self.max_angle)\n",
        "      for i in range(len(x)):\n",
        "          new_x[i] = vg.rotate(x[i].reshape((-1, 3)), self.axis, angle).reshape(-1)\n",
        "      return new_x, y\n",
        "\n",
        "\n",
        "class GaitEventModel(nn.Module):\n",
        "    def __init__(self, d_in, d_out=1, hidden_dim=128, n_layers=3,  \n",
        "                 dropout=0.25, bidirectional=False):\n",
        "        super(GaitEventModel, self).__init__()\n",
        "        self.gru = nn.GRU(\n",
        "            d_in, hidden_dim, n_layers, \n",
        "            batch_first=True, dropout=dropout,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        if bidirectional:\n",
        "            self.fc = nn.Linear(2*hidden_dim, d_out)\n",
        "        else:\n",
        "            self.fc = nn.Linear(hidden_dim, d_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, _ = self.gru(x) # (batch_size, seq_length, hidden_size)\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def prepare_dataloaders(features, targets, meta, batch_size=64, window=32, stride=8,\n",
        "                        train_transform=None):\n",
        "    ## train, dev, test split\n",
        "    # subject spit: 80% - 10% -10%\n",
        "    subjects = meta['id'].unique()\n",
        "    train_subj = subjects[:round(0.8*len(subjects))] # 34\n",
        "    dev_subj = subjects[round(0.8*len(subjects)):-round(0.1*len(subjects))] # 4\n",
        "    test_subj = subjects[-round(0.1*len(subjects)):] # 4\n",
        "\n",
        "    # split features and targets by subjects\n",
        "    def _create_split(subjects):\n",
        "        mask = meta.id.isin(subjects).values\n",
        "        X = list(it.compress(features, mask))\n",
        "        y = list(it.compress(targets, mask))\n",
        "        return X, y\n",
        "\n",
        "    # calc mean and std of training data for standardization\n",
        "    train_features, train_targets = _create_split(train_subj)\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    for f in train_features:\n",
        "        scaler.partial_fit(f)\n",
        "\n",
        "    train_ds = GaitDataset(train_features, train_targets, scaler=scaler,\n",
        "                           window_size=window, stride=stride, \n",
        "                           transform=train_transform)\n",
        "    dev_ds = GaitDataset(*_create_split(dev_subj), scaler=scaler,\n",
        "                           window_size=window, stride=stride)\n",
        "    test_ds = GaitDataset(*_create_split(test_subj), scaler=scaler,\n",
        "                           window_size=window, stride=stride)\n",
        "\n",
        "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    dev_dl = DataLoader(dev_ds, batch_size=2*batch_size)\n",
        "    test_dl = DataLoader(test_ds, batch_size=2*batch_size)\n",
        "\n",
        "    return train_dl, dev_dl, test_dl, scaler\n",
        "\n",
        "\n",
        "def train_model(model, train_dl, dev_dl, lr=3e-4, epochs=50, wd=.02, pos_weight=100, verbose=False):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    pos_weights = torch.Tensor([pos_weight]).to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights) # sparse event -> weight with a factor of 100\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, \n",
        "                                              steps_per_epoch=len(train_dl), \n",
        "                                              epochs=epochs)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_losses = []\n",
        "        for X, y in train_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            yhat = model(X)#.squeeze()\n",
        "            loss = criterion(yhat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        dev_losses = []\n",
        "        for X, y in dev_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                yhat = model(X)\n",
        "                loss = criterion(yhat, y)\n",
        "                dev_losses.append(loss.item())\n",
        "\n",
        "        train_loss = sum(train_losses) / len(train_losses)\n",
        "        dev_loss = sum(dev_losses) / len(dev_losses)\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch}: train loss={train_loss:.3f}, dev loss={dev_loss:.3f}\")\n",
        "    \n",
        "    return dev_loss\n",
        "\n",
        "def evaluate(model, dl, pos_weight=100):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    pos_weights = torch.Tensor([pos_weight, pos_weight]).to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
        "\n",
        "    losses = []\n",
        "    for X, y in dl:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        with torch.no_grad():\n",
        "            yhat = model(X)\n",
        "            loss = criterion(yhat, y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    avg_loss = sum(losses) / len(losses)\n",
        "    return avg_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-bvAvQNPjHI"
      },
      "source": [
        "## Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR-NDc44YuzY"
      },
      "source": [
        "# Load the data\n",
        "path = Path(\"/content/A multimodal dataset of human gait at different walking speeds\")\n",
        "features, targets, meta = load_dataset(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDsSix5Cbt0g"
      },
      "source": [
        "#randNoise = RandomNoise(0.02) # can be used to augment the training\n",
        "train_dl, dev_dl, test_dl, scaler = prepare_dataloaders(features, targets, meta, batch_size=32,\n",
        "                                                        window=16, stride=3, train_transform=None)\n",
        "in_dim = features[0].shape[-1]\n",
        "out_dim = features[0].shape[-1]\n",
        "\n",
        "model = GaitEventModel(in_dim, out_dim, hidden_dim=32, n_layers=1, dropout=0.2, bidirectional=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cV9n7ORTQ8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "615f78c6-7998-45dd-97b9-6338b9933985"
      },
      "source": [
        "train_model(model, train_dl, dev_dl, epochs=50, lr=0.001, verbose=True, wd=.03)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss=1.398, dev loss=1.389\n",
            "Epoch 1: train loss=1.224, dev loss=1.168\n",
            "Epoch 2: train loss=1.022, dev loss=1.048\n",
            "Epoch 3: train loss=0.915, dev loss=0.974\n",
            "Epoch 4: train loss=0.856, dev loss=0.940\n",
            "Epoch 5: train loss=0.804, dev loss=0.929\n",
            "Epoch 6: train loss=0.753, dev loss=0.843\n",
            "Epoch 7: train loss=0.708, dev loss=0.825\n",
            "Epoch 8: train loss=0.666, dev loss=0.739\n",
            "Epoch 9: train loss=0.629, dev loss=0.722\n",
            "Epoch 10: train loss=0.599, dev loss=0.730\n",
            "Epoch 11: train loss=0.569, dev loss=0.674\n",
            "Epoch 12: train loss=0.542, dev loss=0.658\n",
            "Epoch 13: train loss=0.523, dev loss=0.643\n",
            "Epoch 14: train loss=0.499, dev loss=0.618\n",
            "Epoch 15: train loss=0.484, dev loss=0.642\n",
            "Epoch 16: train loss=0.470, dev loss=0.630\n",
            "Epoch 17: train loss=0.455, dev loss=0.662\n",
            "Epoch 18: train loss=0.448, dev loss=0.596\n",
            "Epoch 19: train loss=0.437, dev loss=0.650\n",
            "Epoch 20: train loss=0.427, dev loss=0.609\n",
            "Epoch 21: train loss=0.425, dev loss=0.642\n",
            "Epoch 22: train loss=0.410, dev loss=0.636\n",
            "Epoch 23: train loss=0.412, dev loss=0.676\n",
            "Epoch 24: train loss=0.401, dev loss=0.607\n",
            "Epoch 25: train loss=0.397, dev loss=0.562\n",
            "Epoch 26: train loss=0.392, dev loss=0.632\n",
            "Epoch 27: train loss=0.387, dev loss=0.590\n",
            "Epoch 28: train loss=0.378, dev loss=0.582\n",
            "Epoch 29: train loss=0.374, dev loss=0.564\n",
            "Epoch 30: train loss=0.373, dev loss=0.578\n",
            "Epoch 31: train loss=0.369, dev loss=0.584\n",
            "Epoch 32: train loss=0.363, dev loss=0.603\n",
            "Epoch 33: train loss=0.362, dev loss=0.617\n",
            "Epoch 34: train loss=0.357, dev loss=0.603\n",
            "Epoch 35: train loss=0.355, dev loss=0.634\n",
            "Epoch 36: train loss=0.350, dev loss=0.652\n",
            "Epoch 37: train loss=0.349, dev loss=0.623\n",
            "Epoch 38: train loss=0.346, dev loss=0.586\n",
            "Epoch 39: train loss=0.344, dev loss=0.650\n",
            "Epoch 40: train loss=0.341, dev loss=0.659\n",
            "Epoch 41: train loss=0.338, dev loss=0.651\n",
            "Epoch 42: train loss=0.338, dev loss=0.662\n",
            "Epoch 43: train loss=0.337, dev loss=0.660\n",
            "Epoch 44: train loss=0.335, dev loss=0.653\n",
            "Epoch 45: train loss=0.333, dev loss=0.667\n",
            "Epoch 46: train loss=0.334, dev loss=0.663\n",
            "Epoch 47: train loss=0.334, dev loss=0.658\n",
            "Epoch 48: train loss=0.333, dev loss=0.659\n",
            "Epoch 49: train loss=0.331, dev loss=0.659\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6594254704231911"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONcMThHwN-_2"
      },
      "source": [
        "# save weights\n",
        "torch.save(model.state_dict(), 'gait_rnn_model_f50_w16_l4_h16.pth')\n",
        "np.save('min_scale', np.stack([scaler.min_, scaler.scale_]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_w3dCuLNxG6"
      },
      "source": [
        "## Use Optuna for hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBoPB-kfPcR3"
      },
      "source": [
        "# Load the data (if not already done)\n",
        "path = Path(\"/content/A multimodal dataset of human gait at different walking speeds\")\n",
        "features, targets, meta = load_dataset(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmuPTF0OCkym"
      },
      "source": [
        "import optuna\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# define objective to optimize\n",
        "def objective(trial):\n",
        "    hidden_dim = trial.suggest_int('hidden_dims', 32, 128, log=True)\n",
        "    bidirectional = True #trial.suggest_categorical('bidirectional', [True, False])\n",
        "    n_layers = trial.suggest_int('n_layers', 2, 4)\n",
        "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
        "    batch_size = trial.suggest_int('batch_size', 32, 256, log=True)\n",
        "    window_size = 32 #trial.suggest_int('window_size', 16, 64, log=True)\n",
        "    stride = trial.suggest_int('stride', 4, 16, log=True)\n",
        "    pos_weight = trial.suggest_int('pos_weight', 50, 200)\n",
        "\n",
        "    train_dl, dev_dl, test_dl = prepare_dataloaders(features, targets, meta,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    window=window_size, \n",
        "                                                    stride=stride)\n",
        "    in_dim = features[0].shape[-1]\n",
        "    out_dim = targets[0].shape[-1]\n",
        "\n",
        "    model = GaitEventModel(in_dim, out_dim, hidden_dim, n_layers, \n",
        "                           dropout, bidirectional)\n",
        "    dev_loss = train_model(model, train_dl, dev_dl, epochs=75, lr=0.001, \n",
        "                           pos_weight=pos_weight)\n",
        "\n",
        "    return dev_loss \n",
        "\n",
        "study = optuna.create_study()\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "study.best_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrSFJGkBOh8Y"
      },
      "source": [
        "##Eval results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcvjrN1mBr8A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "1e82da60-aa35-4410-95f4-2e8e8dc16243"
      },
      "source": [
        "x, y = next(iter(dev_dl))\n",
        "i = 10\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "x,y = x.to(device), y.to(device)\n",
        "model.eval()\n",
        "plt.plot(y.detach().cpu().numpy()[i]);\n",
        "plt.show()\n",
        "y_hat = torch.sigmoid(model(x))[i].detach()\n",
        "y_hat[y_hat < 0.5] = 0\n",
        "plt.plot(y_hat.cpu().numpy());\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAf6WMl_6DEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f51c2c8-bc5b-4a29-b079-3f685bc7be39"
      },
      "source": [
        "# Test score\n",
        "evaluate(model, test_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.577990374163441"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "692EkTBqOwLe"
      },
      "source": [
        "##Use the demo data from DigiGait as test case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzmsW_iJ9Ame",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "af52c6e7-c35d-4bc0-f4b3-ab718d986100"
      },
      "source": [
        "import vg\n",
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "from scipy.signal import butter, filtfilt\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "data = np.load('demo_data.npz', allow_pickle=True)\n",
        "pose = data['pose_3d'][:300]\n",
        "lknee_angle = data['lknee_angle'][:300]\n",
        "rknee_angle = data['lknee_angle'][:300]\n",
        "\n",
        "def draw_skeleton(p, axis=0):\n",
        "    plt.figure(figsize=(5,10))\n",
        "    plt.scatter(p[:, axis], p[:, 2])\n",
        "    for j in range(p.shape[0]):\n",
        "        plt.text(p[j, axis], p[j, 2], str(j), color=\"red\", fontsize=12)\n",
        "    plt.show()\n",
        "\n",
        "def _upscale(data, old_fs=50, new_fs=100):\n",
        "    x = np.linspace(0, 1, len(data))\n",
        "    new_x = np.linspace(0, 1, int(new_fs/old_fs * len(data)))\n",
        "    return interp1d(x, data, 'cubic', axis=0)(new_x)\n",
        "\n",
        "def _debias(pose):\n",
        "    pose = pose.copy()\n",
        "    pose[:, 1:] = pose[:, 1:] - pose[:, [0]]  # all joints relative to pelvis\n",
        "    pose[:, 0] = pose[:, 0] - pose[[0], 0]    # pelvis relative to first frame\n",
        "\n",
        "    femur_len_r = np.linalg.norm(pose[:, 1] - pose[:, 2], axis=-1)\n",
        "    femur_len_l = np.linalg.norm(pose[:, 4] - pose[:, 5], axis=-1)\n",
        "    femur_len = (femur_len_r + femur_len_l) / 2 # avg femur length in each frame\n",
        "    pose = pose / femur_len[:, None, None]      # normalize each frame\n",
        "    return pose\n",
        "\n",
        "def _create_fvec(pose, hip, knee, ankle):\n",
        "    f = np.zeros((len(pose), 6, 3))\n",
        "    f[:, :3] = pose[:, [hip, knee, ankle]]    # position\n",
        "    f[:, 3:] = np.gradient(f[:, :3], axis=0)  # velocity\n",
        "    return f.reshape((len(pose), -1))\n",
        "\n",
        "def _scale(X, feature_range=(-1,1)):  # normalize X to feature range\n",
        "    data_min = np.nanmin(X, axis=0)\n",
        "    data_range = np.nanmax(X, axis=0) - data_min\n",
        "    _scale = (feature_range[1] - feature_range[0]) / data_range\n",
        "    _min = feature_range[0] - data_min * _scale\n",
        "    return X * _scale + _min\n",
        "\n",
        "def _butter_lp_filter(data, lp_freq, order=4, fs=100):\n",
        "    nyq = 0.5 * fs\n",
        "    b, a = butter(order, lp_freq/nyq, btype='low', analog=False)\n",
        "    return filtfilt(b, a, data, axis=0)\n",
        "\n",
        "\n",
        "def _norm_walking_dir(pose):\n",
        "    x_axis = np.array([1,0,0])\n",
        "    z_axis = np.array([0,0,1])\n",
        "\n",
        "    orient = vg.angle((pose[:, 4] - pose[:, 1]), x_axis, look=z_axis)\n",
        "    new_pose = pose.copy()\n",
        "    for i in range(len(pose)):\n",
        "        new_pose[i] = vg.rotate(pose[i], z_axis, orient[i])\n",
        "    return new_pose\n",
        "\n",
        "\n",
        "pose = _debias(_norm_walking_dir(pose)) # _upscale\n",
        "f = _create_fvec(_butter_lp_filter(pose, 7), 1, 2, 3)\n",
        "f = _scale(f)\n",
        "f = torch.Tensor(f[np.newaxis, :, :]).to(device)\n",
        "\n",
        "model.eval()\n",
        "pred = torch.sigmoid(model(f))\n",
        "plt.plot(pred.detach().cpu().squeeze().numpy());\n",
        "\n",
        "\n",
        "#plt.plot(f[:140, :3])\n",
        "#plt.legend('xyz')\n",
        "#plt.show()\n",
        "#plt.plot(red_features[2][:, :3])\n",
        "#plt.legend('xyz')\n",
        "#plt.show();\n",
        "\n",
        "#draw_skeleton(_norm_walking_dir(pose)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}